# The journey begins

It was the promise of intelligent machines that would relieve humanity of many
onerous tasks that provided me the drive to teach myself electronics technology
and computer programming. I am retired now, too soon to participate corporately
in the design and production of these machines but not to late to take up the 
adventure of teaching myself the basics of machine learning and artificial
intelligence.

I made an early attempt last year at learning ML by taking the wonderful, on-line
course in machine learning by Andrew Ng. Unfortunately, the stress of my personal
situation and the demands of my engineering job put an end to that adventure before
I finished the course. 

My situation changed in April when I retired from my engineering career and, after
completing some challenging house maintenance projects, I found myself with time
to take up ML training again.

I first worked my way through the "Machine Learning with Python" course offered by
Free Code Camp.org. I finished the course of study but then was not able to gain
access to the project pages that needed to be completed in order to earn the certificate.

Frustrated, I went looking at various other options.

I thought seriously about taking Andrew Ng's new AI course on Coursera, but, being
retired and living on a fixed income, I decided I couldn't comfortable afford the
$49 a month I would have to pay Coursera. 

Fortunately, I discovered a very good (and free) course offered by Fast.ai titled
"Practical Deep Learning for Coders". So far, I am really enjoying the course and
I feel like I am learning practical skills I can use to complete some personal AI
projects I have been wanting to build for a long time.

I naively thought, as I jumped head-first into this course, that my old IBM 
Thinkstation with 12 processor cores and 24 GB of RAM would be sufficient to do some
serious neural network training.  

# WRONG!

As I attempted to do the exercises in the second set of lessons, I quickly discovered
that I was going to get nowhere in ML without access to a modern graphics processor
unit (GPU). GPUs that will work with Pytourch and the Fast.ai library turned out to 
cost a lot more money than I was willing to part with, especially for a non-essential 
hobby project. :-(

As I looked around at the possibility of renting a modern Nvidia GPU, I quickly discovered
that there are companies which offer free access to remote Linux virtual computers with
GPUs. After a week of looking over the options, I settled on leasing computing power from
Paperspace Gradient. They have a free account that offers access to VCPUs and GPUs but, I
decided that their "Pro" account with access to an 8-core machine and a selection of 
Nvidia GPUs for only $8 a month was a bargain I couldn't pass up.

I am now able to develop my neural nets in a jupyter notebook on my local machine, upload
the notebook and the databases to my Gradient account where I can rapidly finish the 
NN training, then download the NN parameters to run again on my local machine. It gives me
the use of a powerful machine for training neural nets for a meager $8 per month.
Gee! What a bargain Dad!

In the next post, I will work my way through the various challenges I encountered in setting
up my dev environment and getting started with the fast.ai training.

Cheers!

